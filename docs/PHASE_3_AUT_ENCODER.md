# –§–∞–∑–∞ 3: AuT Audio Encoder

–†–µ–∞–ª–∏–∑–∞—Ü–∏—è "—É—à–µ–π" –º–æ–¥–µ–ª–∏ - –∫—Ä–∏—Ç–∏—á–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∞—É–¥–∏–æ.

## –ó–∞–¥–∞—á–∏

### 3.1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ú–æ–¥–µ–ª–∏
- [ ] –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å `AuTEncoderConfig` —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:
    * `d_model`: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (1280 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, 896 –¥–ª—è 0.6B, 1024 –¥–ª—è 1.7B)
    * `encoder_layers`: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ (32)
    * `encoder_attention_heads`: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ attention heads (20)
    * `encoder_ffn_dim`: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å FFN (5120)
    * `num_mel_bins`: –í—Ö–æ–¥–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (128)
    * `downsample_rate`: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç downsampling (8x)
    * `output_token_rate`: –†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∞—è —á–∞—Å—Ç–æ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ (12.5 Hz)
- [ ] –°–æ–∑–¥–∞—Ç—å –∫–∞—Ä–∫–∞—Å `struct AuTEncoder` —Å –ø–æ–ª—è–º–∏ –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤.
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥ `forward()` –¥–ª—è –ø—Ä–æ—Ö–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ —ç–Ω–∫–æ–¥–µ—Ä.

### 3.2. Conv2D Downsampling Block
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–∞—á–∞–ª—å–Ω—ã–π –±–ª–æ–∫ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ–µ–≤ (Conv2D):
    * Input: `[batch, time, 128]` Mel spectrogram
    * Downsampling: 8x —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ Conv2D —Å–ª–æ–µ–≤
    * Output: `[batch, time/8, d_model]` —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (12.5 Hz token rate)
- [ ] –î–æ–±–∞–≤–∏—Ç—å Batch Normalization –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (ReLU/GELU).
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–æ—Å–ª–µ downsampling.

### 3.3. Transformer Encoder Layers
- [ ] **EncoderLayer** - –æ—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞:
    * Pre-LayerNorm –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    * Multi-Head Self-Attention (20 heads)
    * Feed-Forward Network (FFN —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å—é 5120)
    * Residual connections
- [ ] **Multi-Head Attention**:
    * –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π self-attention (–Ω–∞—á–∞—Ç—å —Å —ç—Ç–æ–≥–æ)
    * Flash Attention (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)
    * Dynamic attention windows (1-8 —Å–µ–∫—É–Ω–¥ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
- [ ] **Position-wise FFN**:
    * Linear ‚Üí Activation (GELU) ‚Üí Linear
    * Dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏

### 3.4. –ó–∞–≥—Ä—É–∑–∫–∞ –í–µ—Å–æ–≤
- [ ] –ò–∑—É—á–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤–µ—Å–æ–≤ –≤ `.safetensors` —Ñ–∞–π–ª–µ –º–æ–¥–µ–ª–∏.
- [ ] –°–æ–∑–¥–∞—Ç—å –º—ç–ø–ø–∏–Ω–≥ –∏–º–µ–Ω –≤–µ—Å–æ–≤:
    * PyTorch: `audio_model.encoder.layers.0.self_attn.q_proj.weight`
    * Rust: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –ø–æ–ª–µ –≤ `EncoderLayer`
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `load_from_safetensors()` –º–µ—Ç–æ–¥.
- [ ] –î–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤ (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, dtypes).

### 3.5. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Flash Attention (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ –≤ candle).
- [ ] –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ Metal/CUDA (—á–µ—Ä–µ–∑ candle backend).
- [ ] –î–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É mixed precision (FP16/BF16).

## ‚úÖ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ó–∞–≤–µ—Ä—à–µ–Ω–∏—è (Definition of Done)

- –≠–Ω–∫–æ–¥–µ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ—Å–∞ –∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö `.safetensors` —Ñ–∞–π–ª–æ–≤
- Forward pass –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –≤—ã—Ö–æ–¥ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–π Python-—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (–¥–æ–ø—É—Å–∫ 1e-4)
- –ö–æ–¥ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –Ω–∞ CPU, —Ç–∞–∫ –∏ –Ω–∞ GPU (Metal)
- –ù–∞–ø–∏—Å–∞–Ω—ã unit-—Ç–µ—Å—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ (Conv, Attention, FFN)
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ API

## üìä –ú–µ—Ç—Ä–∏–∫–∏ –£—Å–ø–µ—Ö–∞

- –°–∫–æ—Ä–æ—Å—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: < 0.2 RTF –¥–ª—è –∞—É–¥–∏–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é 10 —Å–µ–∫—É–Ω–¥ –Ω–∞ M1/M2
- –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏: < 2GB –¥–ª—è –º–æ–¥–µ–ª–∏ 1.7B –Ω–∞ FP32
- –¢–æ—á–Ω–æ—Å—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å PyTorch: Cosine Similarity > 0.999

## ‚ö†Ô∏è –†–∏—Å–∫–∏ –∏ –ú–∏—Ç–∏–≥–∞—Ü–∏—è

| –†–∏—Å–∫ | –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å | –í–ª–∏—è–Ω–∏–µ | –ú–∏—Ç–∏–≥–∞—Ü–∏—è |
|------|-------------|---------|-----------|
| –ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–µ–∂–¥—É PyTorch –∏ Rust | –í—ã—Å–æ–∫–∞—è | –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ | –ü–æ—à–∞–≥–æ–≤–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ—è |
| –ü—Ä–æ–±–ª–µ–º—ã —Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π attention | –°—Ä–µ–¥–Ω—è—è | –í—ã—Å–æ–∫–æ–µ | –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ candle-transformers |
| –ù–∏–∑–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ CPU | –°—Ä–µ–¥–Ω—è—è | –°—Ä–µ–¥–Ω–µ–µ | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ GPU (Metal), –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è batch —Ä–∞–∑–º–µ—Ä–∞ |
| –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ Flash Attention –≤ candle | –ù–∏–∑–∫–∞—è | –°—Ä–µ–¥–Ω–µ–µ | –ù–∞—á–∞—Ç—å —Å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ attention, –¥–æ–±–∞–≤–∏—Ç—å Flash –ø–æ–∑–∂–µ |

## üîó –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

### –ó–∞–≤–∏—Å–∏—Ç –æ—Ç:
- **–§–∞–∑–∞ 1**: –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ, candle
- **–§–∞–∑–∞ 2**: Feature Extractor –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### –ë–ª–æ–∫–∏—Ä—É–µ—Ç:
- **–§–∞–∑–∞ 4**: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞ –±–µ–∑ —Ä–∞–±–æ—á–µ–≥–æ —ç–Ω–∫–æ–¥–µ—Ä–∞

## üß™ –ü–ª–∞–Ω –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

1. **Unit-—Ç–µ—Å—Ç—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤**:
   - Conv2D downsampling: –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π –≤—ã—Ö–æ–¥–∞
   - Multi-Head Attention: —Ç–µ—Å—Ç —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ Q, K, V
   - FFN: –ø—Ä–æ–≤–µ—Ä–∫–∞ forward –∏ backward pass
   - Layer Normalization: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å PyTorch

2. **Integration-—Ç–µ—Å—Ç—ã**:
   - –ü–æ–ª–Ω—ã–π forward pass —Å —Å–ª—É—á–∞–π–Ω—ã–º –≤—Ö–æ–¥–æ–º
   - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–∞ —Å PyTorch (layer-by-layer)
   - –¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤ –¥–ª—è –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π (0.6B –∏ 1.7B)

3. **Benchmark-—Ç–µ—Å—Ç—ã**:
   - –ò–∑–º–µ—Ä–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –¥–ª–∏–Ω–∞—Ö –≤—Ö–æ–¥–∞ (100, 500, 1000 frames)
   - –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∑–∫–∏—Ö –º–µ—Å—Ç (attention, FFN, matmul)
   - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ CPU vs Metal performance

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ AuT Encoder

```
Input: Mel Spectrogram [batch, time, 128]
  ‚Üì
Conv2D Downsampling (8x)
  ‚Üí Output: [batch, time/8, d_model] @ 12.5 Hz
  ‚Üì
Positional Embedding
  ‚Üì
Transformer Encoder Layers (√ó32)
  ‚Üí Each Layer:
    - LayerNorm
    - Multi-Head Self-Attention (20 heads)
    - Residual Connection
    - LayerNorm
    - Feed-Forward Network (dim=5120)
    - Residual Connection
  ‚Üì
Final LayerNorm
  ‚Üì
Output: Audio Embeddings [batch, time/8, d_model]
```

## üìê –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

| –ú–æ–¥–µ–ª—å | Encoder Params | d_model | Heads | FFN Dim | Layers |
|--------|----------------|---------|-------|---------|--------|
| 0.6B   | 180M           | 896     | 20    | 5120    | 32     |
| 1.7B   | 300M           | 1024    | 20    | 5120    | 32     |

## üìö –†–µ—Ñ–µ—Ä–µ–Ω—Å—ã

- [Qwen3-ASR Technical Report (arXiv:2601.21337)](https://arxiv.org/html/2601.21337v1)
- [Qwen3-ASR-1.7B Model Card](https://huggingface.co/Qwen/Qwen3-ASR-1.7B)
- [Attention Is All You Need (Transformer Architecture)](https://arxiv.org/abs/1706.03762)
- [Flash Attention Paper](https://arxiv.org/abs/2205.14135)
