# Тест: Квантизированные модели (GGUF)

**Дата**: 11 февраля 2026 (обновлено: 12 февраля 2026)
**Платформа**: macOS, Apple Silicon (Metal)

---

## Параметры теста

| Параметр | Значение |
|----------|----------|
| Аудио | `tmp/hf_compare_31118765/full_16k_mono_60s.wav` |
| Длительность аудио | 60.00 с |
| Формат аудио | WAV, 16 kHz, mono, 16-bit PCM |
| Устройство | Metal (GPU) |
| Язык | Russian (форсированный) |
| Энкодер | AuT (safetensors, BF16) — одинаковый для всех |
| Квантизация | Только декодер Qwen3 (GGUF) |

## Доступные квантизации

| Модель | Квантизация | Размер GGUF | Размер safetensors (baseline) |
|--------|-------------|-------------|-------------------------------|
| Qwen3-ASR 0.6B | Q8_0 | 743 МБ | 1.2 ГБ |
| Qwen3-ASR 0.6B | Q4_0 | 533 МБ | 1.2 ГБ |
| Qwen3-ASR 1.7B | Q8_0 | 2.0 ГБ | 3.5 ГБ |
| Qwen3-ASR 1.7B | Q6K | 1.7 ГБ | 3.5 ГБ |
| Qwen3-ASR 1.7B | Q4_0 | 1.3 ГБ | 3.5 ГБ |

---

## Сводная таблица метрик

### Производительность

| Модель | Квантиз. | Cold Start | Transcribe | Total (wall) | RTF |
|--------|----------|-----------|------------|-------------|-----|
| 0.6B | safetensors | 2.60 с | 6.84 с | 12.84 с | 0.114 |
| 0.6B | **Q8_0** | 2.33 с | 6.83 с | 9.35 с | 0.114 |
| 0.6B | **Q4_0** | 1.26 с | 7.21 с | 8.58 с | 0.120 |
| 1.7B | **Q8_0** | 5.66 с | 11.19 с | 16.98 с | 0.187 |
| 1.7B | **Q6K** | 5.26 с | 13.28 с | 18.74 с | 0.221 |
| 1.7B | **Q4_0** | 4.72 с | 9.36 с | 14.23 с | 0.156 |

### Потребление памяти

| Модель | Квантиз. | Peak RSS | Peak Footprint | Page Faults |
|--------|----------|----------|----------------|-------------|
| 0.6B | safetensors | 1 932 МБ | 7 694 МБ | 23 198 |
| 0.6B | **Q8_0** | 1 929 МБ | 7 694 МБ | 23 388 |
| 0.6B | **Q4_0** | 2 716 МБ | 7 503 МБ | 22 757 |
| 1.7B | **Q8_0** | 4 178 МБ | 10 720 МБ | 38 771 |
| 1.7B | **Q6K** | 5 834 МБ | 10 302 МБ | 38 775 |
| 1.7B | **Q4_0** | 5 264 МБ | 10 014 МБ | 39 218 |

### CPU-нагрузка

| Модель | Квантиз. | User time | Sys time | Instructions | Cycles |
|--------|----------|-----------|----------|-------------|--------|
| 0.6B | safetensors | 1.57 с | 4.07 с | 51.5B | 21.3B |
| 0.6B | **Q8_0** | 1.50 с | 3.80 с | 51.6B | 19.9B |
| 0.6B | **Q4_0** | 1.69 с | 4.21 с | 60.5B | 22.3B |
| 1.7B | **Q8_0** | 1.78 с | 5.05 с | 63.0B | 26.0B |
| 1.7B | **Q6K** | 1.92 с | 5.41 с | 63.3B | 27.7B |
| 1.7B | **Q4_0** | 1.80 с | 4.78 с | 60.4B | 25.0B |

---

## Оценка качества по квантизациям

### Qwen3-ASR 0.6B

| Квантиз. | Ключевые ошибки | Качество |
|----------|----------------|----------|
| safetensors | «Олиной», «видеото», «спортсменов» | ★★★☆☆ |
| **Q8_0** | Идентично safetensors | ★★★☆☆ |
| **Q4_0** | Больше искажений: «вижу, то», «сценария», «свойничудальный» | ★★☆☆☆ |

### Qwen3-ASR 1.7B

| Квантиз. | Ключевые моменты | Качество |
|----------|-----------------|----------|
| **Q8_0** | «пять несчастных случаев» (вместо «пятничной»), «визита», «мтс партнера» ✅ | ★★★★☆ |
| **Q6K** | «пятьничных встреч», «визита», «МТС партнер» ✅ | ★★★★☆ |
| **Q4_0** | «пятьничных встреч», «визитов», «MTS партнеров», «инсультальный» | ★★★☆☆ |

---

## Ключевые выводы

### Скорость
- **Q8_0 не замедляет** инференс по сравнению с safetensors (0.6B: идентичный RTF 0.114)
- **Q4_0 0.6B** загружается быстрее всех (Cold Start 1.26 с вместо 2.60 с) за счёт меньшего размера файла
- **1.7B Q4_0** парадоксально быстрее Q8_0 и Q6K в транскрибации (9.36 с vs 11–13 с)

### Память
- **Квантизация 0.6B** практически не влияет на потребление — GPU footprint доминирует (~7.5–7.7 ГБ)
- **1.7B**: Q4_0 экономит ~700 МБ footprint по сравнению с Q8_0 (10.0 ГБ vs 10.7 ГБ)
- RSS для 1.7B Q6K/Q4_0 парадоксально выше — связано с kernel-side аллокациями при квантизации

### Качество
- **Q8_0 0.6B** — **идеальный вариант**: нулевая потеря качества, быстрая загрузка
- **Q8_0 / Q6K 1.7B** — качество близко к safetensors baseline, 1.7B заметно лучше 0.6B
- **Q4_0** — заметная деградация: искажённые слова, некорректные окончания
- На коротких записях (60 с) Q4_0 **не зацикливается**, но на длинных (265 с) может уходить в повторы

### Рекомендации

| Сценарий | Рекомендация |
|----------|-------------|
| Минимальная потеря качества | Q8_0 (любая модель) |
| Баланс размер/качество | Q6K (только 1.7B) |
| Минимальный размер на диске | Q4_0 + VAD (diarize) для длинных записей |
| Лучшее качество Qwen3 | 1.7B Q8_0 или Q6K |

---

## Команды запуска

```bash
# 0.6B Q8_0
target/release/rustasr transcribe \
  --model models/qwen3-asr-0.6b --device metal --language Russian \
  --decoder-weights gguf --decoder-gguf model-q8_0.gguf \
  --audio <file.wav>

# 0.6B Q4_0
target/release/rustasr transcribe \
  --model models/qwen3-asr-0.6b --device metal --language Russian \
  --decoder-weights gguf --decoder-gguf model-q4_0.gguf \
  --audio <file.wav>

# 1.7B Q8_0
target/release/rustasr transcribe \
  --model models/qwen3-asr-1.7b --device metal --language Russian \
  --decoder-weights gguf --decoder-gguf model-q8_0.gguf \
  --audio <file.wav>

# 1.7B Q6K
target/release/rustasr transcribe \
  --model models/qwen3-asr-1.7b --device metal --language Russian \
  --decoder-weights gguf --decoder-gguf model-q6k.gguf \
  --audio <file.wav>

# 1.7B Q4_0
target/release/rustasr transcribe \
  --model models/qwen3-asr-1.7b --device metal --language Russian \
  --decoder-weights gguf --decoder-gguf model-q4_0.gguf \
  --audio <file.wav>
```

## Логи

- [logs/qwen3_0.6b_q8_0.log](logs/qwen3_0.6b_q8_0.log)
- [logs/qwen3_0.6b_q4_0.log](logs/qwen3_0.6b_q4_0.log)
- [logs/qwen3_1.7b_q8_0.log](logs/qwen3_1.7b_q8_0.log)
- [logs/qwen3_1.7b_q6k.log](logs/qwen3_1.7b_q6k.log)
- [logs/qwen3_1.7b_q4_0.log](logs/qwen3_1.7b_q4_0.log)

---

## Whisper Large v3 Turbo (GGUF)

Квантизированные веса Whisper доступны из репозитория [oxide-lab/whisper-large-v3-turbo-GGUF](https://huggingface.co/oxide-lab/whisper-large-v3-turbo-GGUF).
В отличие от Qwen3, квантизируется **вся модель** (encoder + decoder).

### Доступные квантизации

| Квантизация | Размер GGUF | Размер safetensors (baseline) | Экономия |
|-------------|-------------|-------------------------------|----------|
| Q8_0 | 825 МБ | 1.5 ГБ | –46% |
| Q4_0 | 442 МБ | 1.5 ГБ | –71% |

### Производительность (Metal GPU)

| Квантиз. | Cold Start | Transcribe | Total (wall) | RTF |
|----------|-----------|------------|-------------|-----|
| safetensors | 4.03 с | 6.60 с | 10.67 с | 0.110 |
| **Q8_0** | **1.38 с** | 16.12 с | 17.51 с | 0.269 |
| **Q4_0** | **0.23 с** | 13.99 с | 14.22 с | 0.233 |

### Потребление памяти (Metal GPU)

| Квантиз. | Peak RSS | Peak Footprint | Page Faults |
|----------|----------|----------------|-------------|
| safetensors | 1 711 МБ | 6 984 МБ | 98 552 |
| **Q8_0** | 1 437 МБ | 9 284 МБ | 1 441 |
| **Q4_0** | 1 459 МБ | 8 900 МБ | 994 |

### CPU-нагрузка (Metal GPU)

| Квантиз. | User time | Sys time | Instructions | Cycles |
|----------|-----------|----------|-------------|--------|
| safetensors | 0.33 с | 2.52 с | 23.3B | 10.9B |
| **Q8_0** | 0.86 с | 2.12 с | 33.0B | 11.5B |
| **Q4_0** | 0.84 с | 1.64 с | 32.0B | 9.6B |

### Оценка качества (русский)

| Квантиз. | Ключевые отличия от safetensors | Качество |
|----------|-------------------------------|----------|
| safetensors | Эталон: «блокирующих», «на вашей стороне», «детальный» | ★★★★★ |
| **Q8_0** | Идентично safetensors! Тот же текст, confidence 95%/93% | ★★★★★ |
| **Q4_0** | «облокирующих», «на вашей сцене», «институтальный»; confidence 92%/91% | ★★★★☆ |

### Ключевые выводы (Whisper GGUF)

- **Cold Start**: загрузка GGUF **в 3–17× быстрее** safetensors (0.23–1.38 с vs 4.03 с)
- **RTF**: GGUF **в 2–2.4× медленнее** safetensors (0.233–0.269 vs 0.110) — candle quantized inference менее оптимизирован для Metal
- **Качество Q8_0**: **идентично safetensors** — нулевая потеря
- **Качество Q4_0**: минимальная деградация, некоторые слова искажаются, но текст полностью понятен
- **Рекомендация**: Q8_0 для сценариев частого запуска (сервер) из-за быстрого cold start; safetensors для максимального throughput

### Команды запуска

```bash
# Whisper GGUF Q8_0
target/release/rustasr transcribe \
  --model models/whisper-large-v3-turbo --model-type whisper \
  --audio <file.wav> --device metal --decoder-weights gguf

# Whisper GGUF Q4_0 (убрать Q8_0 из директории или выбрать явно)
target/release/rustasr transcribe \
  --model models/whisper-large-v3-turbo --model-type whisper \
  --audio <file.wav> --device metal --decoder-weights gguf
```

---

## GigaAM / Parakeet — квантизация не поддерживается

На данный момент квантизированные модели GigaAM и Parakeet **не поддерживаются** в RustASR:

- **GigaAM v3 CTC**: engine возвращает ошибку `"GigaAM: квантизированные модели пока не поддерживаются"`. Архитектура (Conformer CTC) не имеет реализации `quantized_model` в `candle-transformers`.
- **Parakeet TDT v3**: engine возвращает ошибку `"Parakeet: квантизированные модели пока не поддерживаются"`. Архитектура (FastConformer TDT) также не имеет квантизированного варианта.

Для обеих моделей квантизация потребует написания собственной `quantized_model` реализации (аналогично `whisper::quantized_model`), конвертации весов safetensors → GGUF и адаптации engine. Это возможная задача, но на данный момент эти модели работают только с safetensors весами.
